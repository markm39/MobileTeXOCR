{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten LaTeX OCR Training\n",
    "\n",
    "Train the unified text spotting model on Google Colab with H100/A100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/markm39/MobileTeXOCR.git\n",
    "%cd MobileTeXOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision pillow numpy pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/MobileTeXOCR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup\n",
    "\n",
    "Choose ONE option below:\n",
    "- **Option A**: Create dummy data (for testing pipeline)\n",
    "- **Option B**: Download real datasets (for actual training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Create Dummy Data (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy dataset for testing the pipeline\n",
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def create_dummy_dataset(base_dir, num_train=100, num_val=20):\n",
    "    \"\"\"Create dummy handwritten math images for testing.\"\"\"\n",
    "    \n",
    "    expressions = [\n",
    "        'x^2', 'y^2', 'x+y', 'a-b', '\\\\frac{1}{2}', '\\\\sqrt{x}',\n",
    "        'x^2+y^2', 'a^2-b^2', '\\\\alpha', '\\\\beta', '\\\\gamma',\n",
    "        '\\\\sum_{i=1}^{n}', '\\\\int_0^1', 'e^x', '\\\\pi r^2',\n",
    "        '\\\\frac{a}{b}', 'x_1', 'y_2', 'z^n', '\\\\theta'\n",
    "    ]\n",
    "    \n",
    "    for split, num_samples in [('train', num_train), ('val', num_val)]:\n",
    "        img_dir = os.path.join(base_dir, 'hme100k', split, 'images')\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "        \n",
    "        labels = {}\n",
    "        for i in range(num_samples):\n",
    "            # Create white image\n",
    "            img = Image.new('RGB', (384, 384), 'white')\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            \n",
    "            # Draw expression (simplified rendering)\n",
    "            expr = expressions[i % len(expressions)]\n",
    "            # Draw some random strokes to simulate handwriting\n",
    "            import random\n",
    "            random.seed(i)\n",
    "            x_start = random.randint(50, 150)\n",
    "            y_start = random.randint(150, 200)\n",
    "            \n",
    "            # Simple text (in real data this would be actual handwriting)\n",
    "            try:\n",
    "                font = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', 40)\n",
    "            except:\n",
    "                font = ImageFont.load_default()\n",
    "            \n",
    "            # Draw display version\n",
    "            display_text = expr.replace('\\\\', '').replace('{', '').replace('}', '').replace('_', '').replace('^', '')\n",
    "            draw.text((x_start, y_start), display_text, fill='black', font=font)\n",
    "            \n",
    "            # Save image\n",
    "            img_name = f'sample_{i:04d}.png'\n",
    "            img.save(os.path.join(img_dir, img_name))\n",
    "            labels[img_name] = expr\n",
    "        \n",
    "        # Save labels\n",
    "        labels_file = os.path.join(base_dir, 'hme100k', split, 'labels.json')\n",
    "        with open(labels_file, 'w') as f:\n",
    "            json.dump(labels, f, indent=2)\n",
    "        \n",
    "        print(f'Created {num_samples} {split} samples in {img_dir}')\n",
    "\n",
    "# Create dummy data\n",
    "create_dummy_dataset('./data', num_train=100, num_val=20)\n",
    "print('Dummy dataset created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Download Real Datasets (for actual training)\n",
    "\n",
    "Uncomment and run the cells below to download real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download MathWriting dataset (630K samples) - requires gsutil auth\n",
    "# !pip install gsutil\n",
    "# !mkdir -p data/mathwriting\n",
    "# !gsutil -m cp -r gs://mathwriting_data/train ./data/mathwriting/\n",
    "# !gsutil -m cp -r gs://mathwriting_data/val ./data/mathwriting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download CROHME from Kaggle (requires Kaggle API key)\n",
    "# !pip install kaggle\n",
    "# !mkdir -p ~/.kaggle\n",
    "# # Upload your kaggle.json or set credentials\n",
    "# !kaggle datasets download -d xainano/handwrittenmathsymbols\n",
    "# !unzip -q handwrittenmathsymbols.zip -d data/crohme/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternative: Download from HuggingFace (if available)\n",
    "# !pip install huggingface_hub\n",
    "# from huggingface_hub import snapshot_download\n",
    "# snapshot_download(repo_id=\"ybelkada/im2latex-100k\", local_dir=\"./data/hme100k\", repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import HandwrittenLaTeXOCR, ModelConfig\n",
    "from models.decoder.tokenizer import LaTeXTokenizer\n",
    "from data import DatasetConfig, CombinedDataset, get_train_transforms, get_eval_transforms\n",
    "from training import Trainer, TrainingConfig\n",
    "\n",
    "tokenizer = LaTeXTokenizer()\n",
    "print(f'Tokenizer vocab size: {tokenizer.vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "# Use 'small' for testing, 'base' for real training\n",
    "ENCODER = 'fastvithd'\n",
    "ENCODER_SIZE = 'small'  # Change to 'base' for full training\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    encoder_type=ENCODER,\n",
    "    encoder_size=ENCODER_SIZE,\n",
    "    image_size=384,\n",
    "    d_model=256 if ENCODER_SIZE == 'small' else 384,\n",
    "    num_decoder_layers=4 if ENCODER_SIZE == 'small' else 6,\n",
    "    freeze_encoder=True,\n",
    ")\n",
    "\n",
    "model = HandwrittenLaTeXOCR(model_config)\n",
    "print(f'Model parameters: {model.count_parameters():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "dataset_config = DatasetConfig(data_dir='./data', image_size=384)\n",
    "\n",
    "train_transform = get_train_transforms(image_size=384, augment_strength='medium')\n",
    "valid_transform = get_eval_transforms(image_size=384)\n",
    "\n",
    "# Check available datasets\n",
    "import os\n",
    "available_datasets = []\n",
    "for ds in ['mathwriting', 'crohme', 'hme100k']:\n",
    "    if os.path.exists(f'./data/{ds}'):\n",
    "        available_datasets.append(ds)\n",
    "\n",
    "print(f'Available datasets: {available_datasets}')\n",
    "\n",
    "if not available_datasets:\n",
    "    raise RuntimeError('No datasets found! Run the dataset setup cells above first.')\n",
    "\n",
    "train_dataset = CombinedDataset(\n",
    "    dataset_config, split='train', transform=train_transform, \n",
    "    tokenizer=tokenizer, datasets=available_datasets\n",
    ")\n",
    "val_dataset = CombinedDataset(\n",
    "    dataset_config, split='val', transform=valid_transform, \n",
    "    tokenizer=tokenizer, datasets=available_datasets\n",
    ")\n",
    "\n",
    "print(f'Train samples: {len(train_dataset)}')\n",
    "print(f'Val samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "    BATCH_SIZE = 48 if gpu_memory > 70e9 else (32 if gpu_memory > 40e9 else 16)\n",
    "else:\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "training_config = TrainingConfig(\n",
    "    output_dir='/content/drive/MyDrive/latex_ocr_outputs',\n",
    "    experiment_name=f'latex_ocr_{ENCODER}_{ENCODER_SIZE}',\n",
    "    num_epochs=5 if len(train_dataset) < 1000 else 20,  # Fewer epochs for dummy data\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100 if len(train_dataset) < 1000 else 2000,\n",
    "    gradient_accumulation_steps=2,\n",
    "    use_amp=True,\n",
    "    amp_dtype='bfloat16' if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else 'float16',\n",
    "    save_steps=500,\n",
    "    validation_steps=100 if len(train_dataset) < 1000 else 1000,\n",
    "    log_steps=10 if len(train_dataset) < 1000 else 100,\n",
    "    freeze_encoder_epochs=1,\n",
    "    early_stopping_patience=5,\n",
    ")\n",
    "\n",
    "print(f'Batch size: {BATCH_SIZE}')\n",
    "print(f'Epochs: {training_config.num_epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = train_dataset.get_dataloader(\n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_workers=2, \n",
    "    use_weighted_sampling=len(train_dataset) > 0\n",
    ")\n",
    "val_loader = val_dataset.get_dataloader(\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=2, \n",
    "    use_weighted_sampling=False\n",
    ")\n",
    "\n",
    "print(f'Train batches: {len(train_loader)}')\n",
    "print(f'Val batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    config=training_config, \n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print('Starting training...')\n",
    "best_metric = trainer.train()\n",
    "print(f'Training complete! Best metric: {best_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "save_path = training_config.output_dir + '/final_model'\n",
    "model.save_pretrained(save_path)\n",
    "print(f'Saved model to {save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get a sample from validation set\n",
    "    sample = val_dataset[0]\n",
    "    img = sample.image.unsqueeze(0).to(device)\n",
    "    \n",
    "    output = model(img)\n",
    "    \n",
    "    print(f'Ground truth: {sample.latex}')\n",
    "    if output.predictions and output.predictions[0]:\n",
    "        pred_latex = output.predictions[0][0][1] if output.predictions[0][0] else ''\n",
    "        print(f'Predicted: {pred_latex}')\n",
    "    else:\n",
    "        print('No prediction generated')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {"gpuType": "T4", "provenance": []},
  "kernelspec": {"display_name": "Python 3", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
