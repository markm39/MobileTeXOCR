{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T11Z0kvX1Lq"
      },
      "source": [
        "# Handwritten LaTeX OCR Training\n",
        "\n",
        "Train the unified text spotting model on Google Colab with H100/A100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGL7EBAuX1Lr",
        "outputId": "05792961-4903-4d58-d322-b9768600ef38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 20 21:28:07 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA H100 80GB HBM3          Off |   00000000:04:00.0 Off |                    0 |\n",
            "| N/A   36C    P0            114W /  700W |       0MiB /  81559MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM4H2OfrX1Lr",
        "outputId": "f69b42cc-d799-4858-b7c4-abf830285c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dAdecmeX1Lr",
        "outputId": "00ee4172-31bd-4b21-c2e5-53f5bcb395db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MobileTeXOCR' already exists and is not an empty directory.\n",
            "/content/MobileTeXOCR\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/markm39/MobileTeXOCR.git\n",
        "%cd MobileTeXOCR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/MobileTeXOCR && git pull\n"
      ],
      "metadata": {
        "id": "RcT6PFe_TQvs",
        "outputId": "97a56f60-eb0b-4038-ebf1-603ea85c4d6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xgKt3q4kX1Lr"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision pillow numpy pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf MobileTeXOCR\n",
        "!git clone https://github.com/markm39/MobileTeXOCR.git\n",
        "%cd MobileTeXOCR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQTQM92QE8O2",
        "outputId": "4673f0ee-5938-472d-d912-c1a0b74f20a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MobileTeXOCR'...\n",
            "remote: Enumerating objects: 48108, done.\u001b[K\n",
            "remote: Counting objects: 100% (206/206), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 48108 (delta 162), reused 144 (delta 135), pack-reused 47902 (from 3)\u001b[K\n",
            "Receiving objects: 100% (48108/48108), 389.75 MiB | 62.27 MiB/s, done.\n",
            "Resolving deltas: 100% (33526/33526), done.\n",
            "/content/MobileTeXOCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B-vk-0NKX1Lr"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/MobileTeXOCR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19E0f5nqX1Lr"
      },
      "source": [
        "## Dataset Setup\n",
        "\n",
        "Choose ONE option below:\n",
        "- **Option A**: Create dummy data (for testing pipeline)\n",
        "- **Option B**: Download real datasets (for actual training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2VPGVMVX1Lr"
      },
      "source": [
        "### Option A: Create Dummy Data (for testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H6yJV3iX1Lr",
        "outputId": "6d0a238b-245b-4038-b605-963ef344c52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 100 train samples in ./data/hme100k/train/images\n",
            "Created 20 val samples in ./data/hme100k/val/images\n",
            "Dummy dataset created!\n"
          ]
        }
      ],
      "source": [
        "# Create dummy dataset for testing the pipeline\n",
        "import os\n",
        "import json\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def create_dummy_dataset(base_dir, num_train=100, num_val=20):\n",
        "    \"\"\"Create dummy handwritten math images for testing.\"\"\"\n",
        "\n",
        "    expressions = [\n",
        "        'x^2', 'y^2', 'x+y', 'a-b', '\\\\frac{1}{2}', '\\\\sqrt{x}',\n",
        "        'x^2+y^2', 'a^2-b^2', '\\\\alpha', '\\\\beta', '\\\\gamma',\n",
        "        '\\\\sum_{i=1}^{n}', '\\\\int_0^1', 'e^x', '\\\\pi r^2',\n",
        "        '\\\\frac{a}{b}', 'x_1', 'y_2', 'z^n', '\\\\theta'\n",
        "    ]\n",
        "\n",
        "    for split, num_samples in [('train', num_train), ('val', num_val)]:\n",
        "        img_dir = os.path.join(base_dir, 'hme100k', split, 'images')\n",
        "        os.makedirs(img_dir, exist_ok=True)\n",
        "\n",
        "        labels = {}\n",
        "        for i in range(num_samples):\n",
        "            # Create white image\n",
        "            img = Image.new('RGB', (384, 384), 'white')\n",
        "            draw = ImageDraw.Draw(img)\n",
        "\n",
        "            # Draw expression (simplified rendering)\n",
        "            expr = expressions[i % len(expressions)]\n",
        "            # Draw some random strokes to simulate handwriting\n",
        "            import random\n",
        "            random.seed(i)\n",
        "            x_start = random.randint(50, 150)\n",
        "            y_start = random.randint(150, 200)\n",
        "\n",
        "            # Simple text (in real data this would be actual handwriting)\n",
        "            try:\n",
        "                font = ImageFont.truetype('/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', 40)\n",
        "            except:\n",
        "                font = ImageFont.load_default()\n",
        "\n",
        "            # Draw display version\n",
        "            display_text = expr.replace('\\\\', '').replace('{', '').replace('}', '').replace('_', '').replace('^', '')\n",
        "            draw.text((x_start, y_start), display_text, fill='black', font=font)\n",
        "\n",
        "            # Save image\n",
        "            img_name = f'sample_{i:04d}.png'\n",
        "            img.save(os.path.join(img_dir, img_name))\n",
        "            labels[img_name] = expr\n",
        "\n",
        "        # Save labels\n",
        "        labels_file = os.path.join(base_dir, 'hme100k', split, 'labels.json')\n",
        "        with open(labels_file, 'w') as f:\n",
        "            json.dump(labels, f, indent=2)\n",
        "\n",
        "        print(f'Created {num_samples} {split} samples in {img_dir}')\n",
        "\n",
        "# Create dummy data\n",
        "create_dummy_dataset('./data', num_train=100, num_val=20)\n",
        "print('Dummy dataset created!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlVnJPuNX1Ls"
      },
      "source": [
        "### Option B: Download Real Datasets (for actual training)\n",
        "\n",
        "Run ONE or more of the cells below to download real data. MathWriting is recommended as the primary dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-NWZzw2X1Ls",
        "outputId": "2e2f9dc2-d84b-4e40-8a30-53a9a557292e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mathwriting.tgz     100%[===================>]   2.88G   323MB/s    in 9.4s    \n",
            "MathWriting directory structure:\n",
            "total 620228\n",
            "drwxr-xr-x 7 root   root       4096 Jan 20 21:29 .\n",
            "drwxr-xr-x 4 root   root       4096 Jan 20 21:29 ..\n",
            "-rw-r----- 1 218859 89939      7780 Jan 31  2024 readme.md\n",
            "drwxr-x--- 2 218859 89939    270336 Jan 31  2024 symbols\n",
            "-rw-r----- 1 218859 89939    523063 Jan 31  2024 symbols.jsonl\n",
            "drwxr-x--- 2 218859 89939  18432000 Jan 31  2024 synthetic\n",
            "-rw-r----- 1 218859 89939 604019016 Jan 31  2024 synthetic-bboxes.jsonl\n",
            "drwxr-x--- 2 218859 89939    339968 Jan 31  2024 test\n",
            "drwxr-x--- 2 218859 89939  10747904 Jan 31  2024 train\n",
            "drwxr-x--- 2 218859 89939    745472 Jan 31  2024 valid\n"
          ]
        }
      ],
      "source": [
        "# Download MathWriting dataset (230K human + 400K synthetic samples, 2.9GB)\n",
        "# This is the largest handwritten math expression dataset\n",
        "!mkdir -p data/mathwriting\n",
        "!wget -q --show-progress https://storage.googleapis.com/mathwriting_data/mathwriting-2024.tgz -O mathwriting.tgz\n",
        "!tar -xzf mathwriting.tgz -C data/\n",
        "!rm mathwriting.tgz\n",
        "\n",
        "# Check structure and reorganize if needed\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# The tarball extracts to mathwriting-2024/, we need mathwriting/\n",
        "if os.path.exists('data/mathwriting-2024') and not os.path.exists('data/mathwriting/train'):\n",
        "    # Move contents\n",
        "    for item in os.listdir('data/mathwriting-2024'):\n",
        "        src = f'data/mathwriting-2024/{item}'\n",
        "        dst = f'data/mathwriting/{item}'\n",
        "        if os.path.exists(dst):\n",
        "            shutil.rmtree(dst) if os.path.isdir(dst) else os.remove(dst)\n",
        "        shutil.move(src, dst)\n",
        "    os.rmdir('data/mathwriting-2024')\n",
        "\n",
        "print('MathWriting directory structure:')\n",
        "!ls -la data/mathwriting/ | head -20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "R0iEkajfX1Ls"
      },
      "outputs": [],
      "source": [
        "# # Download CROHME from Kaggle (requires Kaggle API key)\n",
        "# !pip install kaggle\n",
        "# !mkdir -p ~/.kaggle\n",
        "# # Upload your kaggle.json or set credentials\n",
        "# !kaggle datasets download -d xainano/handwrittenmathsymbols\n",
        "# !unzip -q handwrittenmathsymbols.zip -d data/crohme/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FcF3LBt2X1Ls"
      },
      "outputs": [],
      "source": [
        "# # Alternative: Download from HuggingFace (if available)\n",
        "# !pip install huggingface_hub\n",
        "# from huggingface_hub import snapshot_download\n",
        "# snapshot_download(repo_id=\"ybelkada/im2latex-100k\", local_dir=\"./data/hme100k\", repo_type=\"dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AnwuIUmX1Ls"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQx6MytFX1Ls",
        "outputId": "839e6d9a-ae80-41f7-b31f-09329b45fe24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA H100 80GB HBM3\n",
            "Memory: 85.2 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyNHNXC7X1Ls",
        "outputId": "fce2f87c-99e1-4853-a77e-3bfe72dd7e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab size: 1294\n"
          ]
        }
      ],
      "source": [
        "from models import HandwrittenLaTeXOCR, ModelConfig\n",
        "from models.decoder.tokenizer import LaTeXTokenizer\n",
        "from data import DatasetConfig, CombinedDataset, get_train_transforms, get_eval_transforms\n",
        "from training import Trainer, TrainingConfig\n",
        "\n",
        "tokenizer = LaTeXTokenizer()\n",
        "print(f'Tokenizer vocab size: {tokenizer.vocab_size}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpwbBUn9X1Ls",
        "outputId": "d863864b-df4a-4caf-bd75-180b831f269c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 15,195,406\n"
          ]
        }
      ],
      "source": [
        "# Model configuration\n",
        "# Use 'small' for testing, 'base' for real training\n",
        "ENCODER = 'fastvithd'\n",
        "ENCODER_SIZE = 'base'  # Change to 'base' for full training\n",
        "\n",
        "model_config = ModelConfig(\n",
        "    encoder_type=ENCODER,\n",
        "    encoder_size=ENCODER_SIZE,\n",
        "    image_size=384,\n",
        "    d_model=256 if ENCODER_SIZE == 'small' else 384,\n",
        "    num_decoder_layers=4 if ENCODER_SIZE == 'small' else 6,\n",
        "    freeze_encoder=True,\n",
        ")\n",
        "\n",
        "model = HandwrittenLaTeXOCR(model_config)\n",
        "print(f'Model parameters: {model.count_parameters():,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCunEgrEX1Ls",
        "outputId": "a340bb06-6ba2-4726-c08b-548293fb7c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available datasets: ['mathwriting', 'hme100k']\n",
            "Train samples: 229964\n",
            "Val samples: 15694\n"
          ]
        }
      ],
      "source": [
        "# Dataset configuration\n",
        "dataset_config = DatasetConfig(data_dir='./data', image_size=384)\n",
        "\n",
        "train_transform = get_train_transforms(image_size=384, augment_strength='medium')\n",
        "valid_transform = get_eval_transforms(image_size=384)\n",
        "\n",
        "# Check available datasets\n",
        "import os\n",
        "available_datasets = []\n",
        "for ds in ['mathwriting', 'crohme', 'hme100k']:\n",
        "    if os.path.exists(f'./data/{ds}'):\n",
        "        available_datasets.append(ds)\n",
        "\n",
        "print(f'Available datasets: {available_datasets}')\n",
        "\n",
        "if not available_datasets:\n",
        "    raise RuntimeError('No datasets found! Run the dataset setup cells above first.')\n",
        "\n",
        "train_dataset = CombinedDataset(\n",
        "    dataset_config, split='train', transform=train_transform,\n",
        "    tokenizer=tokenizer, datasets=available_datasets\n",
        ")\n",
        "val_dataset = CombinedDataset(\n",
        "    dataset_config, split='val', transform=valid_transform,\n",
        "    tokenizer=tokenizer, datasets=available_datasets\n",
        ")\n",
        "\n",
        "print(f'Train samples: {len(train_dataset)}')\n",
        "print(f'Val samples: {len(val_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UidZmqAeX1Ls",
        "outputId": "0590d2a8-b7e8-47e5-c5b1-06ac6b8bfcc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch size: 96\n",
            "Epochs: 20\n"
          ]
        }
      ],
      "source": [
        "# Training configuration\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "    BATCH_SIZE = 96 if gpu_memory > 70e9 else (32 if gpu_memory > 40e9 else 16)\n",
        "else:\n",
        "    BATCH_SIZE = 4\n",
        "\n",
        "training_config = TrainingConfig(\n",
        "    output_dir='/content/drive/MyDrive/latex_ocr_outputs',\n",
        "    experiment_name=f'latex_ocr_{ENCODER}_{ENCODER_SIZE}',\n",
        "    num_epochs=5 if len(train_dataset) < 1000 else 20,  # Fewer epochs for dummy data\n",
        "    batch_size=BATCH_SIZE,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=100 if len(train_dataset) < 1000 else 2000,\n",
        "    gradient_accumulation_steps=2,\n",
        "    use_amp=True,\n",
        "    amp_dtype='bfloat16' if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else 'float16',\n",
        "    save_steps=500,\n",
        "    validation_steps=100 if len(train_dataset) < 1000 else 1000,\n",
        "    log_steps=10 if len(train_dataset) < 1000 else 100,\n",
        "    freeze_encoder_epochs=1,\n",
        "    early_stopping_patience=5,\n",
        ")\n",
        "\n",
        "print(f'Batch size: {BATCH_SIZE}')\n",
        "print(f'Epochs: {training_config.num_epochs}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAPZrpdbX1Ls",
        "outputId": "0eb163b9-9f51-4997-a08d-b425b182ce7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 2396\n",
            "Val batches: 164\n"
          ]
        }
      ],
      "source": [
        "# Create dataloaders\n",
        "train_loader = train_dataset.get_dataloader(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=2,\n",
        "    use_weighted_sampling=len(train_dataset) > 0\n",
        ")\n",
        "val_loader = val_dataset.get_dataloader(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    use_weighted_sampling=False\n",
        ")\n",
        "\n",
        "print(f'Train batches: {len(train_loader)}')\n",
        "print(f'Val batches: {len(val_loader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmTSCI3xX1Ls"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_nd7051_afoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwJrvyBWX1Ls",
        "outputId": "d805d61c-d8b8-464b-fa3b-29cdd3530d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Starting training: 20 epochs, 2396 batches/epoch\n",
            "Epoch 0: Encoder frozen\n",
            "Step 100: loss=6.6145, lr=3.48e-06\n",
            "Step 200: loss=5.9626, lr=5.95e-06\n",
            "Step 300: loss=5.5109, lr=8.43e-06\n",
            "Step 400: loss=5.2729, lr=1.09e-05\n",
            "Step 500: loss=4.9977, lr=1.34e-05\n",
            "Step 600: loss=4.7054, lr=1.59e-05\n",
            "Step 700: loss=4.4679, lr=1.83e-05\n",
            "Step 800: loss=4.3911, lr=2.08e-05\n",
            "Step 900: loss=4.1543, lr=2.33e-05\n",
            "Step 1000: loss=4.0816, lr=2.58e-05\n",
            "Step 1100: loss=4.1243, lr=2.82e-05\n",
            "Step 1200: loss=3.9988, lr=3.07e-05\n",
            "Step 1300: loss=3.8649, lr=3.32e-05\n",
            "Step 1400: loss=3.9985, lr=3.57e-05\n",
            "Step 1500: loss=3.6639, lr=3.81e-05\n",
            "Step 1600: loss=3.6628, lr=4.06e-05\n",
            "Step 1700: loss=3.7225, lr=4.31e-05\n",
            "Step 1800: loss=3.6716, lr=4.56e-05\n",
            "Step 1900: loss=3.6063, lr=4.80e-05\n",
            "Step 2000: loss=3.5979, lr=5.05e-05\n",
            "Step 2100: loss=3.3311, lr=5.30e-05\n",
            "Step 2200: loss=3.3845, lr=5.55e-05\n",
            "Step 2300: loss=3.2461, lr=5.79e-05\n",
            "Epoch 0 train: {'loss': 4.320017835035149}\n",
            "Epoch 0 val: {'exp_rate': 0.0002548744743213967, 'symbol_accuracy': 0.20942085269331517, 'bleu': 0.01314460886617234, 'loss': 3.668466742445783}\n",
            "Epoch 1: Encoder unfrozen\n",
            "Step 2400: loss=3.2913, lr=6.04e-05\n",
            "Step 2500: loss=3.2408, lr=6.29e-05\n",
            "Step 2600: loss=3.3312, lr=6.54e-05\n",
            "Step 2700: loss=3.0728, lr=6.78e-05\n",
            "Step 2800: loss=3.1761, lr=7.03e-05\n",
            "Step 2900: loss=3.1060, lr=7.28e-05\n",
            "Step 3000: loss=3.1471, lr=7.53e-05\n",
            "Step 3100: loss=2.8308, lr=7.77e-05\n",
            "Step 3200: loss=3.1985, lr=8.02e-05\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    config=training_config,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Resume from latest checkpoint\n",
        "import glob\n",
        "checkpoints = glob.glob('/content/drive/MyDrive/latex_ocr_outputs/latex_ocr_fa\n",
        "stvithd_base/checkpoints/step_*.pt')\n",
        "if checkpoints:\n",
        "    latest = max(checkpoints, key=lambda x:\n",
        "int(x.split('_')[-1].split('.')[0]))\n",
        "    print(f'Resuming from {latest}')\n",
        "    trainer.load_checkpoint(latest)\n",
        "\n",
        "print('Starting training...')\n",
        "best_metric = trainer.train()\n",
        "print(f'Training complete! Best metric: {best_metric:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jP5300XsPqzk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6V3dUENX1Ls"
      },
      "outputs": [],
      "source": [
        "# Save final model\n",
        "save_path = training_config.output_dir + '/final_model'\n",
        "model.save_pretrained(save_path)\n",
        "print(f'Saved model to {save_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bmVm6LlX1Ls"
      },
      "source": [
        "## Test Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXvtcXS4X1Ls"
      },
      "outputs": [],
      "source": [
        "# Test on a sample\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Get a sample from validation set\n",
        "    sample = val_dataset[0]\n",
        "    img = sample.image.unsqueeze(0).to(device)\n",
        "\n",
        "    output = model(img)\n",
        "\n",
        "    print(f'Ground truth: {sample.latex}')\n",
        "    if output.predictions and output.predictions[0]:\n",
        "        pred_latex = output.predictions[0][0][1] if output.predictions[0][0] else ''\n",
        "        print(f'Predicted: {pred_latex}')\n",
        "    else:\n",
        "        print('No prediction generated')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "H100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}