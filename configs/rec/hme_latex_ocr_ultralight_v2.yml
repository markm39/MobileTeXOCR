# HME LaTeX OCR V2 - Ultra-Light with Modern Architectures
# Target: <10MB, <50ms on iPhone 14
# Features:
#   - Proper autoregressive generation (SOS/EOS fixed)
#   - Differential Attention (ICLR 2025)
#   - Mixture of Experts FFN
#   - Shifted labels for true teacher forcing

Global:
  use_gpu: True
  epoch_num: 300
  log_smooth_window: 20
  print_batch_step: 100
  save_model_dir: ./output/rec/hme_ultralight_v2/
  save_epoch_step: 10
  eval_batch_step: [0, 100]  # Temporarily set to 100 to test eval; change back to 2000 after verification
  cal_metric_during_train: False
  pretrained_model:
  checkpoints:
  save_inference_dir: ./inference/hme_ultralight_v2/
  use_visualdl: True
  infer_img: doc/datasets/crohme_demo/hme_00.jpg
  character_dict_path: ppocr/utils/dict/latex_symbol_dict.txt
  max_text_length: 256
  infer_mode: False
  use_space_char: False
  save_res_path: ./output/rec/predicts_hme_ultralight_v2.txt

Optimizer:
  name: AdamW
  beta1: 0.9
  beta2: 0.999
  epsilon: 1.0e-8
  weight_decay: 0.01
  lr:
    name: Cosine
    learning_rate: 0.0003
    warmup_epoch: 5

Architecture:
  model_type: rec
  algorithm: HMEV2
  in_channels: 1
  Transform:
  Backbone:
    name: HME_SHViT_Tiny
    in_channels: 1
    out_channels: 192
  Head:
    name: HMEHeadV2
    in_channels: 192
    vocab_size: 113
    d_model: 192
    nhead: 4
    num_decoder_layers: 2
    d_ffn: 512
    dropout: 0.1
    use_moe: False
    num_experts: 2
    moe_top_k: 1
    use_mamba: False
    attention_type: standard  # Options: standard, differential, path
    max_len: 256

Loss:
  name: HMELossV2
  vocab_size: 113
  label_smoothing: 0.1
  aux_loss_weight: 0.01

PostProcess:
  name: CANLabelDecodeV2

Metric:
  name: CANMetricV2
  main_indicator: exp_rate

Train:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/CROHME/training/images/
    label_file_list: ["./train_data/CROHME/training/labels.txt"]
    transforms:
      - DecodeImage:
          channel_first: False
      - NormalizeImage:
          mean: [0, 0, 0]
          std: [1, 1, 1]
          order: 'hwc'
      - GrayImageChannelFormat:
          inverse: True
      - CANLabelEncodeV2:
          lower: False
      - KeepKeys:
          keep_keys: ['image', 'decoder_input', 'decoder_target']
  loader:
    shuffle: True
    batch_size_per_card: 16
    drop_last: True
    num_workers: 4
    collate_fn: DyMaskCollatorV2

Eval:
  dataset:
    name: SimpleDataSet
    data_dir: ./train_data/CROHME/evaluation/images/
    label_file_list: ["./train_data/CROHME/evaluation/labels.txt"]
    transforms:
      - DecodeImage:
          channel_first: False
      - NormalizeImage:
          mean: [0, 0, 0]
          std: [1, 1, 1]
          order: 'hwc'
      - GrayImageChannelFormat:
          inverse: True
      - CANLabelEncodeV2:
          lower: False
      - KeepKeys:
          keep_keys: ['image', 'decoder_input', 'decoder_target']
  loader:
    shuffle: False
    drop_last: False
    batch_size_per_card: 1
    num_workers: 4
    collate_fn: DyMaskCollatorV2
