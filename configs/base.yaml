# Base configuration for Handwritten LaTeX OCR training

# Model settings
model:
  encoder_type: fastvithd  # fastvithd or perception
  encoder_size: base       # small, base for fastvithd; tiny for perception
  image_size: 384
  d_model: 384
  num_decoder_layers: 6
  num_heads: 8
  freeze_encoder: false

# Data settings
data:
  data_dir: ./data
  datasets:
    - mathwriting
    - crohme
    - hme100k
  image_size: 384
  max_seq_length: 512
  num_location_bins: 1000
  augment_strength: medium  # light, medium, heavy

# Training settings
training:
  output_dir: ./outputs
  experiment_name: latex_ocr_base
  num_epochs: 20
  batch_size: 32
  gradient_accumulation_steps: 2
  max_grad_norm: 1.0

# Optimizer settings
optimizer:
  learning_rate: 1.0e-4
  weight_decay: 0.01
  warmup_steps: 2000
  lr_scheduler: cosine  # cosine, linear, constant

# Mixed precision
amp:
  enabled: true
  dtype: float16  # float16 or bfloat16

# Checkpointing
checkpointing:
  save_steps: 2000
  validation_steps: 1000
  save_total_limit: 3

# Logging
logging:
  log_steps: 100
  use_wandb: false
  wandb_project: latex-ocr

# Early stopping
early_stopping:
  patience: 5
  metric: exp_rate

# Encoder training strategy
encoder_training:
  freeze_encoder_epochs: 1  # Freeze encoder for first N epochs
